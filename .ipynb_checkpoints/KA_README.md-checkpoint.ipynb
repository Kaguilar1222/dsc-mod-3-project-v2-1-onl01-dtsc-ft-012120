{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "For the Module 3 Project, I performed a supervised binary classification exercise on a dataset to predict whether a household earns below or above the median household income in the Philippines. \n",
    "\n",
    "My aim as a Data Science student with this exercise is to identify the features of a household that are the strongest indicators of whether a family is earning above the median through several different modeling techniques. \n",
    "\n",
    "## Libraries\n",
    "For data cleaning/exploration: Pandas\n",
    "For plotting: Matplotlib.pyplot, Seaborn\n",
    "For modeling: scikit-learn, XGBoost\n",
    "\n",
    "# The Dataset \n",
    "The Family Income and Expenditure Survey (FIES) from 2015 is available [here on Kaggle](https://www.kaggle.com/grosvenpaul/family-income-and-expenditure) consists of over 40K rows and 60 columns and is collected by the Philippine Statistics Authority every three years. \n",
    "\n",
    "## Target\n",
    "**Total Household Income** consists of continuous data which I initially converted into two classes (0/1), with 1 indicating that a makes above the median income. \n",
    "\n",
    "## Features\n",
    "The 59 features are all descriptive of households through spend, household structure, possessions, and living conditions, as I categorize them below. \n",
    "\n",
    "* **Expenditures**: Total Food Expenditure, Bread and Cereals Expenditure, Total Rice Expenditure, Meat Expenditure, Total Fish and  marine products Expenditure, Fruit Expenditure,Vegetables Expenditure, Restaurant and hotels Expenditure, Alcoholic Beverages Expenditure, Tobacco Expenditure, Clothing, Footwear and Other Wear Expenditure, Housing and water Expenditure, Transportation Expenditure, Communication Expenditure, Education Expenditure, Miscellaneous Goods and Services Expenditure, Special Occasions Expenditure, Medical Care Expenditure, Crop Farming and Gardening expenses\n",
    "* **Household Descriptions**: Region, Main Source of Income, Agricultural Household indicator, Imputed House Rental Value, Total Income from Entrepreneurial Acitivites, Household Head Sex, Household Head Age, Household Head Marital Status, Household Head Highest Grade Completed, Household Head Job or Business Indicator, Household Head Occupation, Household Head Class of Worker, Type of Household,Total Number of Family members, Members with age less than 5 year old, Members with age 5 - 17 years old, Total number of family members employed\n",
    "* **Possessions**: Number of Television, Number of CD/VCD/DVD, Number of Component/Stereo set, Number of Refrigerator/Freezer, Number of Washing Machine,Number of Airconditioner, Number of Car, Jeep, Van, Number of Landline/wireless telephones, Number of Cellular phone, Number of Personal Computer, Number of Stove with Oven/Gas Range, Number of Motorized Banca, Number of Motorcycle/Tricycle\n",
    "* **Living Conditions**:Type of Building/House, Type of Roof,Type of Walls, House Floor Area, House Age,Number of bedrooms, Tenure Status, Toilet Facilities, Electricity,Main Source of Water Supply,\n",
    "\n",
    "# EDA\n",
    "\n",
    "I eliminated 10 columns during my EDA phase in three phases. \n",
    "1) Object columns with missing values\n",
    "2) Object columns with no clear correlation with Household Income based on a countplot\n",
    "3) Continuous columns with very few non-zero values\n",
    "\n",
    "I also converted several columns from object values to one-hot encoded variables where there was a high likelihood of correlation between a variable and income.\n",
    "\n",
    "# Modeling \n",
    "\n",
    "I used scikit-learn's train-test split (70/30) to enable model validation for every estimator, and used Pipeline to condense normalization/estimation/grid searching for all models except for LogisticRegression.\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "For my baseline model I used LogisticRegression, which takes our predictors and calculates the probability of belonging to a groupin order to classify a datapoint. \n",
    "\n",
    "To improve on this estimator I used Recursive Feature Elimination to identify any further removal of features, using a for loop to identify the number to keep that leaves us with the highest f1 score. I continued to use these 40 variables throughout the remaining models.\n",
    "\n",
    "Notably, these models provided the highest precision scores, so of all predicted positives, a high percentage of those predictions were correct.\n",
    "\n",
    "## K-Nearest Neighbors\n",
    "Next, I used K-Nearest Neighbors, a classification method wherein labels are predicted based on the labels of training data that is \"closest\" to the model validation datapoint. Through a for loop to determine the best F1 score, I made predictions using 21 neighbors. \n",
    "\n",
    "This model performed the most poorly amongst all models that I used, and achieved an F1 score of .8395, although as with our prior models, % of predicted positives being labeled correctly remains high. \n",
    "\n",
    "## Decision Tree\n",
    "My next model was a decision tree with no hyperparameters, as I was looking to see what kind of fit could be achieved with a decision tree being allowed to run wild. \n",
    "\n",
    "As predicted, this resulted in an extremely granular decision tree, and slightly better performance than prior models on recall(sensitivity), which makes sense for such an overfit model. However, this model performed poorer than either Logistic Regression models. \n",
    "\n",
    "\n",
    "## Random Forest\n",
    "Next, I used Random Forest, an ensemble method in which a specified number of estimators(decision trees, in this case) are created, each one using a different sample and set of features. In my first iteration of a Random Forest classifier, I created 100 estimators and used a max depth of 10. As I still have a comparatively high number of variables at 40, I am letting the trees have at least 10 layers of nodes before stopping. \n",
    "\n",
    "To iterate on this, I added a Grid Search in order to tune the hyperparameters (i.e. explore options for pruning the size of the tree). I tuned the max depth, the minimum size of a sample that can be split, and the minimum leaf size. Surprisingly, keeping no limit to the max_depth produced the best performing model with our test set, and this model performed well across score types. \n",
    "\n",
    "## XGBoost\n",
    "\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "Dataframe of the scores of each model\n",
    "\n",
    "\n",
    " - \"Why did you select those visualizations and what did you learn from each of them?\"\n",
    " - \"Why did you pick those features as predictors?\"\n",
    " - \"How would you interpret the results?\"\n",
    " - \"How confident are you in the predictive quality of the results?\"\n",
    " - \"What are some of the things that could cause the results to be wrong?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
